{"cells":[{"cell_type":"markdown","metadata":{"id":"TkXgSCs__gl5"},"source":["# **Mount the Drive**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14796,"status":"ok","timestamp":1696858905289,"user":{"displayName":"ROHAN POPHALE","userId":"01363560878617152113"},"user_tz":-330},"id":"wSPMDi-m_p1_","outputId":"df43cc23-9dc8-49fb-c0cf-4650cf19a3d4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"Hm39a-CuAFFZ"},"source":["# **Import the libraries**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4xjOY9K3_s9g"},"outputs":[],"source":["#import the libraries\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1696871161223,"user":{"displayName":"ROHAN POPHALE","userId":"01363560878617152113"},"user_tz":-330},"id":"KzmamjVBAVs4","outputId":"17747ba0-5933-47f0-ca4c-ad5dbe871d8c"},"outputs":[{"output_type":"stream","name":"stdout","text":["---------------------Tweet data---------------------\n","\n","  sentiment                                               text\n","0  Positive                    I am so happy to see you again \n","1  Positive                               what a wonderful day\n","2  Positive  im getting on borderlands and i will murder yo...\n","3  Positive  I am coming to the borders and I will kill you...\n","4  Positive  im getting on borderlands and i will kill you ...\n","5  Positive  im coming on borderlands and i will murder you...\n","6  Positive  im getting on borderlands 2 and i will murder ...\n","7  Positive  im getting into borderlands and i can murder y...\n","8  Positive  So I spent a few hours making something for fu...\n","9  Positive  So I spent a couple of hours doing something f...\n"]}],"source":["tweetdata = pd.read_csv(\"/content/drive/MyDrive/DSL Project/Datasets/twitter_training_10000_new.csv\")\n","\n","print(\"---------------------Tweet data---------------------\\n\")\n","print(tweetdata.head(10))"]},{"cell_type":"markdown","metadata":{"id":"qluihkbwBpkl"},"source":["# **Know the datsets**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1696871167352,"user":{"displayName":"ROHAN POPHALE","userId":"01363560878617152113"},"user_tz":-330},"id":"oDcqZ8ulBJXd","outputId":"956a4435-8eb1-414c-d192-b966aeaa605e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tweet datset :  (9999, 2)\n"]}],"source":["#check for the shape of the datset\n","print(\"Tweet datset : \" ,tweetdata.shape)"]},{"cell_type":"markdown","metadata":{"id":"jmCL-L4IM4_y"},"source":["# **Cleaning the datasetS (Base Level Preprocessing)**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1696871171780,"user":{"displayName":"ROHAN POPHALE","userId":"01363560878617152113"},"user_tz":-330},"id":"SUDC0pU-CN_w","outputId":"f175df31-5930-48ae-d65b-dce52eb1e5a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tweet datset :  sentiment      0\n","text         112\n","dtype: int64\n"]}],"source":["#check for null dataset\n","print(\"Tweet datset : \" ,tweetdata.isnull().sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1696871175902,"user":{"displayName":"ROHAN POPHALE","userId":"01363560878617152113"},"user_tz":-330},"id":"4r4m_-x8C4ce","outputId":"0a2413a1-8b87-486b-e6ae-25e824f0626d"},"outputs":[{"output_type":"stream","name":"stdout","text":["--------------------Tweet dataset-------------------------\n","\n","       sentiment text\n","63       Neutral  NaN\n","555      Neutral  NaN\n","591      Neutral  NaN\n","747     Positive  NaN\n","1107    Positive  NaN\n","...          ...  ...\n","9933    Negative  NaN\n","9934    Negative  NaN\n","9989  Irrelevant  NaN\n","9990  Irrelevant  NaN\n","9991  Irrelevant  NaN\n","\n","[112 rows x 2 columns]\n"]}],"source":["#displaying the row which contains the null values\n","tweetdata_row_with_null = tweetdata[tweetdata.isnull().any(axis=1)]\n","print(\"--------------------Tweet dataset-------------------------\\n\")\n","print(tweetdata_row_with_null)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1696871179663,"user":{"displayName":"ROHAN POPHALE","userId":"01363560878617152113"},"user_tz":-330},"id":"amf2sn9pFFlC","outputId":"0ba46cfa-c7eb-42d2-ddd0-280d150b7f23"},"outputs":[{"output_type":"stream","name":"stdout","text":["cleaned_tweetdata :  sentiment    0\n","text         0\n","dtype: int64\n"]}],"source":["#drop the null values\n","cleaned_tweetdata = tweetdata.dropna()\n","\n","print(\"cleaned_tweetdata : \",cleaned_tweetdata.isnull().sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1696871183262,"user":{"displayName":"ROHAN POPHALE","userId":"01363560878617152113"},"user_tz":-330},"id":"r6crA9syM20M","outputId":"c0775d51-2ae5-4bc4-c7e1-842fa619c71f"},"outputs":[{"output_type":"stream","name":"stdout","text":["  sentiment                                               text\n","0  Positive                    I am so happy to see you again \n","1  Positive                               what a wonderful day\n","2  Positive  im getting on borderlands and i will murder yo...\n","3  Positive  I am coming to the borders and I will kill you...\n","4  Positive  im getting on borderlands and i will kill you ...\n","5  Positive  im coming on borderlands and i will murder you...\n","6  Positive  im getting on borderlands 2 and i will murder ...\n","7  Positive  im getting into borderlands and i can murder y...\n","8  Positive  So I spent a few hours making something for fu...\n","9  Positive  So I spent a couple of hours doing something f...\n","\n"]}],"source":["print(cleaned_tweetdata.head(10))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1696871185177,"user":{"displayName":"ROHAN POPHALE","userId":"01363560878617152113"},"user_tz":-330},"id":"Ehu9WQ0hGhCQ","outputId":"d2a58280-6bb3-4211-be13-58700031d1f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cleaned Tweet dataset :  (9887, 2)\n"]}],"source":["#checking the shape of cleaned datasets\n","print(\"Cleaned Tweet dataset : \",cleaned_tweetdata.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":457,"status":"ok","timestamp":1696871187944,"user":{"displayName":"ROHAN POPHALE","userId":"01363560878617152113"},"user_tz":-330},"id":"mWOA0vaKHJVQ","outputId":"2f0de6f4-40b5-4c7b-e0d4-24cfd4f5b37b"},"outputs":[{"output_type":"stream","name":"stdout","text":["(9999, 2) \t (9887, 2)\n"]}],"source":["#Comparing the shape of old and new datasets\n","print(tweetdata.shape,\"\\t\",cleaned_tweetdata.shape)"]},{"cell_type":"markdown","metadata":{"id":"UmlHsTLQI44w"},"source":["# **Advanced data preprocessing by text preprocessing**\n","\n","\n","1.   Removing Special Characters and Punctuation\n","2.   Converting Text to Lowercase\n","3. Removing Stop Words\n","4. Stemming or Lemmatization\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":436,"status":"ok","timestamp":1696871193178,"user":{"displayName":"ROHAN POPHALE","userId":"01363560878617152113"},"user_tz":-330},"id":"TSf6E4dsH1FG","outputId":"8100a7be-7fe7-454d-870a-7fdd7c11128e"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":220}],"source":["#import the required libraries for text processing\n","import pandas as pd\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import PorterStemmer\n","import string\n","import datetime  # Import the datetime library\n","\n","nltk.download('punkt')\n","nltk.download('stopwords')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ANTLR2n6L8aw"},"outputs":[],"source":["# Define a function for text preprocessing\n","def preprocess_text(text):\n","    # Remove special characters and punctuation\n","    text = ''.join([char for char in text if char not in string.punctuation])\n","\n","    # Tokenization\n","    tokens = word_tokenize(text)\n","\n","    # Convert to lowercase\n","    tokens = [word.lower() for word in tokens]\n","\n","    # Remove stop words\n","    stop_words = set(stopwords.words('english'))\n","    filtered_tokens = [word for word in tokens if word not in stop_words]\n","\n","    # Stemming (optional)\n","    stemmer = PorterStemmer()\n","    stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n","\n","    return ' '.join(stemmed_tokens)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7385,"status":"ok","timestamp":1696871205944,"user":{"displayName":"ROHAN POPHALE","userId":"01363560878617152113"},"user_tz":-330},"id":"ZwSgL7QDMJHH","outputId":"76000619-47af-4db4-b0f2-0a24284a130a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Execution time for the cleaned_tweetdata :  0:00:07.009967\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-222-8d7ebba356b6>:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  cleaned_tweetdata.loc[:, 'text'] = cleaned_tweetdata['text'].apply(preprocess_text)\n"]}],"source":["# Apply the preprocessing function to the entire 'text' column in your DataFrame\n","#measuring the time for the tweetdataset\n","start_time1 = datetime.datetime.now()\n","cleaned_tweetdata.loc[:, 'text'] = cleaned_tweetdata['text'].apply(preprocess_text)\n","end_time1 = datetime.datetime.now()\n","\n","#calculating the execution time for the tweet dataset\n","execution_time1 = end_time1 - start_time1\n","\n","#displaying the execution time for the both datasets\n","exe_time_tweetdata = execution_time1\n","\n","print(\"Execution time for the cleaned_tweetdata : \", exe_time_tweetdata)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":506,"status":"ok","timestamp":1696871210111,"user":{"displayName":"ROHAN POPHALE","userId":"01363560878617152113"},"user_tz":-330},"id":"IiHv6ezPMjxJ","outputId":"6a164943-a2f4-4acd-f618-a74af5611023"},"outputs":[{"output_type":"stream","name":"stdout","text":["  sentiment                                               text\n","0  Positive                                          happi see\n","1  Positive                                         wonder day\n","2  Positive                           im get borderland murder\n","3  Positive                                   come border kill\n","4  Positive                             im get borderland kill\n","5  Positive                          im come borderland murder\n","6  Positive                         im get borderland 2 murder\n","7  Positive                           im get borderland murder\n","8  Positive  spent hour make someth fun dont know huge bord...\n","9  Positive  spent coupl hour someth fun dont know im huge ...\n"]}],"source":["# Print the cleaned DataFrame\n","print(cleaned_tweetdata.head(10))"]},{"cell_type":"markdown","metadata":{"id":"2EkfcHYOdrCw"},"source":["# **Split the datasets into train and test**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1696871214461,"user":{"displayName":"ROHAN POPHALE","userId":"01363560878617152113"},"user_tz":-330},"id":"fx-lXLSvd2br","outputId":"f4d9a2f2-3583-45ab-ccf4-b29587060baf"},"outputs":[{"output_type":"stream","name":"stdout","text":["------------------------------------Size of the datasets of the Tweet Datasets--------------------------------------\n","\n","Training set size: 7142 samples\n","Validation set size: 1261 samples\n","Test set size: 1484 samples\n"]}],"source":["#import the libraries\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","# Define the features (X) and the target labels (y)\n","X1 = cleaned_tweetdata['text']\n","y1 = cleaned_tweetdata['sentiment']\n","\n","X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.15, random_state=30)\n","X_train1, X_val1, y_train1, y_val1 = train_test_split(X_train1, y_train1, test_size=0.15, random_state=30)\n","\n","# Print the sizes of the subsets\n","print(\"------------------------------------Size of the datasets of the Tweet Datasets--------------------------------------\\n\")\n","print(f\"Training set size: {len(X_train1)} samples\")\n","print(f\"Validation set size: {len(X_val1)} samples\")\n","print(f\"Test set size: {len(X_test1)} samples\")"]},{"cell_type":"markdown","source":["# **Vectorization**"],"metadata":{"id":"H177GjoENjeE"}},{"cell_type":"code","source":["#import the libraries\n","import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import pickle\n","\n","# Vectorize the text data using TF-IDF(cleaned_tweetdata)\n","vectorizer = TfidfVectorizer(max_features=1000)  # You can adjust the max_features parameter\n","X_train1_tfidf = vectorizer.fit_transform(X_train1)\n","X_val1_tfidf = vectorizer.transform(X_val1)\n","X_test1_tfidf = vectorizer.transform(X_test1)\n","\n","#pickeling\n","# Fit the vectorizer with your training data (X_train1 and X_train2)\n","vectorizer.fit(X_train1)  # Fit with cleaned_tweetdata training data\n","\n","# Save the fitted vectorizer\n","with open(\"tfidf_10000_vectorizer.pkl\", \"wb\") as f:\n","    pickle.dump(vectorizer, f)"],"metadata":{"id":"ikEoWpHENnKc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Logistic Regression Model**"],"metadata":{"id":"mchQiqW14LsX"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":681,"status":"ok","timestamp":1696871280905,"user":{"displayName":"ROHAN POPHALE","userId":"01363560878617152113"},"user_tz":-330},"id":"SMIb45AHgQuN","outputId":"1ca1bc63-4105-456c-abec-245546a85485"},"outputs":[{"output_type":"stream","name":"stdout","text":["------------------------------------------Model evaluation with the cleaned_tweetdata (logistic)----------------------------------------------------\n","\n","\n","-----------------------------------Accuracy---------------------------------------\n","\n","Test Accuracy: 0.6913746630727763\n","\n","----------------------Classification report---------------------------------------\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","  Irrelevant       0.69      0.53      0.60       283\n","    Negative       0.71      0.73      0.72       347\n","     Neutral       0.75      0.61      0.67       391\n","    Positive       0.65      0.82      0.73       463\n","\n","    accuracy                           0.69      1484\n","   macro avg       0.70      0.68      0.68      1484\n","weighted avg       0.70      0.69      0.69      1484\n","\n","\n","-------------------------Confusion Matrix---------------------------------------\n","\n","Confusion Matrix:\n"," [[150  30  31  72]\n"," [ 17 255  25  50]\n"," [ 22  44 240  85]\n"," [ 27  29  26 381]]\n","\n","-----------------------------------------Model evaluation with the cleaned_tweetdata ends (logistic)-----------------------------------------------\n","\n"]}],"source":["#import the libraries\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Train a logistic regression model(cleaned_tweetdata)\n","Logistic_Tweet_model= LogisticRegression(max_iter=200, random_state=100)\n","Logistic_Tweet_model.fit(X_train1_tfidf, y_train1)\n","\n","# Make predictions on the test set\n","y_test1_pred = Logistic_Tweet_model.predict(X_test1_tfidf)\n","\n","# Evaluate the model on the test set\n","accuracy1_logistic = accuracy_score(y_test1, y_test1_pred)\n","report1_logistic = classification_report(y_test1, y_test1_pred)\n","conf_matrix1_logistic = confusion_matrix(y_test1, y_test1_pred)\n","\n","#printing the results\n","print(\"------------------------------------------Model evaluation with the cleaned_tweetdata (logistic)----------------------------------------------------\\n\")\n","print(\"\\n-----------------------------------Accuracy---------------------------------------\\n\")\n","print(f\"Test Accuracy: {accuracy1_logistic}\")\n","print(\"\\n----------------------Classification report---------------------------------------\\n\")\n","print(\"Classification Report:\\n\", report1_logistic)\n","print(\"\\n-------------------------Confusion Matrix---------------------------------------\\n\")\n","print(\"Confusion Matrix:\\n\", conf_matrix1_logistic)\n","print(\"\\n-----------------------------------------Model evaluation with the cleaned_tweetdata ends (logistic)-----------------------------------------------\\n\")"]},{"cell_type":"markdown","metadata":{"id":"B-nO2jgQyOI2"},"source":["# **Support Vector Machine (SVM)**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5216,"status":"ok","timestamp":1696871291364,"user":{"displayName":"ROHAN POPHALE","userId":"01363560878617152113"},"user_tz":-330},"id":"rUN3YakDtVhf","outputId":"cd3b413c-0212-4593-8424-3bb12a1487ec"},"outputs":[{"output_type":"stream","name":"stdout","text":["------------------------------------------Model evaluation with the cleaned_tweetdata (SVM)----------------------------------------------------\n","\n","\n","-----------------------------------Accuracy---------------------------------------\n","\n","Test Accuracy: 0.7115902964959568\n","\n","----------------------Classification report---------------------------------------\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","  Irrelevant       0.69      0.59      0.63       283\n","    Negative       0.74      0.76      0.75       347\n","     Neutral       0.81      0.62      0.70       391\n","    Positive       0.66      0.83      0.73       463\n","\n","    accuracy                           0.71      1484\n","   macro avg       0.72      0.70      0.70      1484\n","weighted avg       0.72      0.71      0.71      1484\n","\n","\n","-------------------------Confusion Matrix---------------------------------------\n","\n","Confusion Matrix:\n"," [[166  26  20  71]\n"," [ 19 262  19  47]\n"," [ 26  39 244  82]\n"," [ 30  29  20 384]]\n","\n","-----------------------------------------Model evaluation with the cleaned_tweetdata (SVM) ends-----------------------------------------------\n","\n"]}],"source":["from sklearn.svm import SVC\n","\n","# Train an SVM classifier for cleaned_tweetdata\n","Tweet_svm_model = SVC(kernel='linear', C=1.0)  # You can experiment with different kernels and C values\n","Tweet_svm_model.fit(X_train1_tfidf, y_train1)\n","\n","# Make predictions on the test set for cleaned_tweetdata\n","y_test1_svm_pred = Tweet_svm_model.predict(X_test1_tfidf)\n","\n","# Evaluate the SVM model on the test set for cleaned_tweetdata\n","accuracy1_svm = accuracy_score(y_test1, y_test1_svm_pred)\n","report1_svm = classification_report(y_test1, y_test1_svm_pred)\n","conf_matrix1_svm = confusion_matrix(y_test1, y_test1_svm_pred)\n","\n","# Printing the results for SVM\n","print(\"------------------------------------------Model evaluation with the cleaned_tweetdata (SVM)----------------------------------------------------\\n\")\n","print(\"\\n-----------------------------------Accuracy---------------------------------------\\n\")\n","print(f\"Test Accuracy: {accuracy1_svm}\")\n","print(\"\\n----------------------Classification report---------------------------------------\\n\")\n","print(\"Classification Report:\\n\", report1_svm)\n","print(\"\\n-------------------------Confusion Matrix---------------------------------------\\n\")\n","print(\"Confusion Matrix:\\n\", conf_matrix1_svm)\n","print(\"\\n-----------------------------------------Model evaluation with the cleaned_tweetdata (SVM) ends-----------------------------------------------\\n\")"]},{"cell_type":"markdown","metadata":{"id":"Nujplmcq-Oy9"},"source":["# **Random Forest Method**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UgIyjZQ--ULr","executionInfo":{"status":"ok","timestamp":1696871304014,"user_tz":-330,"elapsed":5334,"user":{"displayName":"ROHAN POPHALE","userId":"01363560878617152113"}},"outputId":"bbfd47b7-6d2b-4188-aa28-8ce28520a05c"},"outputs":[{"output_type":"stream","name":"stdout","text":["------------------------------------------Model evaluation with the cleaned_tweetdata (Random Forest)----------------------------------------------------\n","\n","\n","-----------------------------------Accuracy---------------------------------------\n","\n","Test Accuracy: 0.8592\n","\n","----------------------Classification report---------------------------------------\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","  Irrelevant       0.87      0.80      0.83       283\n","    Negative       0.89      0.85      0.87       347\n","     Neutral       0.90      0.86      0.88       391\n","    Positive       0.80      0.90      0.85       463\n","\n","    accuracy                           0.86      1484\n","   macro avg       0.87      0.85      0.86      1484\n","weighted avg       0.86      0.86      0.86      1484\n","\n","\n","-------------------------Confusion Matrix---------------------------------------\n","\n","Confusion Matrix:\n"," [[226  10  11  36]\n"," [ 13 296  10  28]\n"," [ 10   7 335  39]\n"," [ 11  18  16 418]]\n","\n","-----------------------------------------Model evaluation with the cleaned_tweetdata ends (Random Forest)-----------------------------------------------\n","\n"]}],"source":["#import the libraries\n","from sklearn.ensemble import RandomForestClassifier\n","\n","# Train a Random Forest model (cleaned_tweetdata)\n","RandomForest_Tweet_model = RandomForestClassifier(n_estimators=100, random_state=30)\n","RandomForest_Tweet_model.fit(X_train1_tfidf, y_train1)\n","\n","# Make predictions on the test set\n","y_test1_pred = RandomForest_Tweet_model.predict(X_test1_tfidf)\n","\n","# Evaluate the model on the test set\n","accuracy1_rf = accuracy_score(y_test1, y_test1_pred)\n","report1_rf = classification_report(y_test1, y_test1_pred)\n","conf_matrix1_rf = confusion_matrix(y_test1, y_test1_pred)\n","\n","# Printing the results for Random Forest\n","print(\"------------------------------------------Model evaluation with the cleaned_tweetdata (Random Forest)----------------------------------------------------\\n\")\n","print(\"\\n-----------------------------------Accuracy---------------------------------------\\n\")\n","print(f\"Test Accuracy: {accuracy1_rf:.4f}\")\n","print(\"\\n----------------------Classification report---------------------------------------\\n\")\n","print(\"Classification Report:\\n\", report1_rf)\n","print(\"\\n-------------------------Confusion Matrix---------------------------------------\\n\")\n","print(\"Confusion Matrix:\\n\", conf_matrix1_rf)\n","print(\"\\n-----------------------------------------Model evaluation with the cleaned_tweetdata ends (Random Forest)-----------------------------------------------\\n\")"]},{"cell_type":"markdown","metadata":{"id":"WvVEQKcEFevv"},"source":["# **Naive Bayes (MultinomialNB)**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":571,"status":"ok","timestamp":1696871339174,"user":{"displayName":"ROHAN POPHALE","userId":"01363560878617152113"},"user_tz":-330},"id":"qsJhSKDWFpNz","outputId":"f9511e52-15e6-4d3d-c50e-168ff9ceff57"},"outputs":[{"output_type":"stream","name":"stdout","text":["------------------------------------------Model evaluation with the cleaned_tweetdata (Naive Bayes)----------------------------------------------------\n","\n","\n","-----------------------------------Accuracy---------------------------------------\n","\n","Test Accuracy: 0.6361\n","\n","----------------------Classification report---------------------------------------\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","  Irrelevant       0.73      0.35      0.47       283\n","    Negative       0.69      0.69      0.69       347\n","     Neutral       0.78      0.51      0.61       391\n","    Positive       0.55      0.88      0.67       463\n","\n","    accuracy                           0.64      1484\n","   macro avg       0.68      0.61      0.61      1484\n","weighted avg       0.67      0.64      0.62      1484\n","\n","\n","-------------------------Confusion Matrix---------------------------------------\n","\n","Confusion Matrix:\n"," [[ 99  37  25 122]\n"," [  7 240  14  86]\n"," [ 20  45 198 128]\n"," [ 10  28  18 407]]\n","\n","-----------------------------------------Model evaluation with the cleaned_tweetdata ends (Naive Bayes)-----------------------------------------------\n","\n"]}],"source":["# Import the libraries\n","from sklearn.naive_bayes import MultinomialNB\n","\n","# Train a Naive Bayes model (cleaned_tweetdata)\n","NaiveBayes_Tweet_model = MultinomialNB()\n","NaiveBayes_Tweet_model.fit(X_train1_tfidf, y_train1)\n","\n","# Make predictions on the test set\n","y_test1_pred = NaiveBayes_Tweet_model.predict(X_test1_tfidf)\n","\n","# Evaluate the model on the test set\n","accuracy1_nb = accuracy_score(y_test1, y_test1_pred)\n","report1_nb = classification_report(y_test1, y_test1_pred)\n","conf_matrix1_nb = confusion_matrix(y_test1, y_test1_pred)\n","\n","# Printing the results for Naive Bayes\n","print(\"------------------------------------------Model evaluation with the cleaned_tweetdata (Naive Bayes)----------------------------------------------------\\n\")\n","print(\"\\n-----------------------------------Accuracy---------------------------------------\\n\")\n","print(f\"Test Accuracy: {accuracy1_nb:.4f}\")\n","print(\"\\n----------------------Classification report---------------------------------------\\n\")\n","print(\"Classification Report:\\n\", report1_nb)\n","print(\"\\n-------------------------Confusion Matrix---------------------------------------\\n\")\n","print(\"Confusion Matrix:\\n\", conf_matrix1_nb)\n","print(\"\\n-----------------------------------------Model evaluation with the cleaned_tweetdata ends (Naive Bayes)-----------------------------------------------\\n\")"]},{"cell_type":"markdown","metadata":{"id":"jWuFscGJK1bB"},"source":["# **Accuracy comparison of all models**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1696871342239,"user":{"displayName":"ROHAN POPHALE","userId":"01363560878617152113"},"user_tz":-330},"id":"z2IVVyC2Bsv_","outputId":"101bd0dc-543e-4a10-da50-f76c218027d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["===============================Accuracy comparison========================================\n","\n","-----------------------------------------For Tweet data---------------------------------------------------\n","\n","Logistic Regression Accuracy (Tweet Data): 0.6913746630727763\n","SVM Accuracy (Tweet Data): 0.7115902964959568\n","Random Forest Accuracy (Tweet Data): 0.8591644204851752\n","Naive Bayes Accuracy (Tweet Data): 0.6361185983827493\n"]}],"source":["print(\"===============================Accuracy comparison========================================\")\n","print(\"\\n-----------------------------------------For Tweet data---------------------------------------------------\\n\")\n","print(\"Logistic Regression Accuracy (Tweet Data):\", accuracy1_logistic)\n","print(\"SVM Accuracy (Tweet Data):\", accuracy1_svm)\n","print(\"Random Forest Accuracy (Tweet Data):\", accuracy1_rf)\n","print(\"Naive Bayes Accuracy (Tweet Data):\", accuracy1_nb)"]},{"cell_type":"markdown","metadata":{"id":"BiHStfStUOeM"},"source":["# **Accuracy in the % form**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1696871345194,"user":{"displayName":"ROHAN POPHALE","userId":"01363560878617152113"},"user_tz":-330},"id":"tNuZ930rMEtw","outputId":"f96f6274-7118-4379-eb7a-0e2938ac93e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["===============================Accuracy comparison========================================\n","\n","-----------------------------------------For Tweet data---------------------------------------------------\n","\n","Logistic Regression Accuracy (Tweet Data): 77.254%\n","SVM Accuracy (Tweet Data): 80.888%\n","Random Forest Accuracy (Tweet Data): 89.098%\n","Naive Bayes Accuracy (Tweet Data): 69.852%\n","========================================================================================\n"]}],"source":["# Original accuracy values\n","tweet_data_accuracies = {\n","    \"Logistic Regression\": 0.7725437415881561,\n","    \"SVM\":  0.8088829071332436,\n","    \"Random Forest\": 0.8909825033647375,\n","    \"Naive Bayes\":0.6985195154777928,\n","}\n","\n","# Convert accuracies to percentages with 3 decimal places\n","tweet_data_accuracies_percent = {model: accuracy * 100 for model, accuracy in tweet_data_accuracies.items()}\n","\n","# Display accuracies in percentage format\n","print(\"===============================Accuracy comparison========================================\\n\")\n","print(\"-----------------------------------------For Tweet data---------------------------------------------------\\n\")\n","for model, accuracy in tweet_data_accuracies_percent.items():\n","    print(f\"{model} Accuracy (Tweet Data): {accuracy:.3f}%\")\n","\n","print(\"========================================================================================\")\n"]},{"cell_type":"markdown","metadata":{"id":"ji0HAKSfVLqn"},"source":["# **Conclusion**\n","based on the accuracy comparison of same dataset but different no of entries (0 to 100, 0 to 500, 0 to 1000, 0 to 5000, 0 to 10000, 0 to 50000 and 0 to 70000), it appears that for the Tweet dataset **Random Forest** is giving the highest accuracy with the range of **(0.84 - 0.92) or (84 - 92 %)** hence the RandomForest algorithm will use for the **Sentiment Analysis.**"]},{"cell_type":"markdown","source":["# **Saving the model**"],"metadata":{"id":"2YEJvnVouB8T"}},{"cell_type":"code","source":["#import the libraries\n","import pickle\n","\n","with open(\"RandomForest_Tweet_10000_model.model\",\"wb\") as f:\n","    pickle.dump(RandomForest_Tweet_model,f)\n","\n","print(\"Model saved\")"],"metadata":{"id":"9uasx8i4ikjb","executionInfo":{"status":"ok","timestamp":1696871312488,"user_tz":-330,"elapsed":700,"user":{"displayName":"ROHAN POPHALE","userId":"01363560878617152113"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"93e35710-be9c-4c54-c50c-5d48d098864a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model saved\n"]}]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1QApOPKZ5ywzglusleXRqMgc4gz83ApD_","authorship_tag":"ABX9TyP/M1iByW/kRtX2ls6pc6T9"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}